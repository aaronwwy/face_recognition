{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition\n",
    "\n",
    "[Face Recognition](https://github.com/ageitgey/face_recognition)\n",
    "\n",
    "## Installation\n",
    "\n",
    "### Requirements\n",
    "\n",
    "  * Python 3.3+ or Python 2.7\n",
    "  * macOS or Linux (Windows not officially supported, but might work)\n",
    "\n",
    "### Installation Options:\n",
    "\n",
    "#### Installing on Mac or Linux\n",
    "\n",
    "First, make sure you have dlib already installed with Python bindings:\n",
    "\n",
    "  * [How to install dlib from source on macOS or Ubuntu](https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf)\n",
    "\n",
    "Then, install this module from pypi using `pip3` (or `pip2` for Python 2):\n",
    "\n",
    "```bash\n",
    "pip3 install face_recognition\n",
    "```\n",
    "\n",
    "If you are having trouble with installation, you can also try out a\n",
    "[pre-configured VM](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b).\n",
    "\n",
    "#### Installing on Raspberry Pi 2+\n",
    "\n",
    "  * [Raspberry Pi 2+ installation instructions](https://gist.github.com/ageitgey/1ac8dbe8572f3f533df6269dab35df65)\n",
    "\n",
    "#### Installing on Windows\n",
    "\n",
    "While Windows isn't officially supported, helpful users have posted instuctions on how to install this library:\n",
    "\n",
    "  * [@masoudr's Windows 10 installation guide (dlib + face_recognition)](https://github.com/ageitgey/face_recognition/issues/175#issue-257710508)\n",
    "\n",
    "#### Installing a pre-configured Virtual Machine image\n",
    "\n",
    "  * [Download the pre-configured VM image](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b) (for VMware Player or VirtualBox)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before get started\n",
    "\n",
    "### Create folders\n",
    "#### known_faces\n",
    "\n",
    "* Create a folder known_faces and put pictures of known people in this folder. The format of picture can be either jpg or jpeg which I've verified however other formats may be supported as well.\n",
    "* Naming convention: name the picture with the actual name of underlying people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "image = face_recognition.load_image_file(\"./unknown_pictures/unknown.jpeg\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "## Find faces from a picture and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Find faces from a picture\n",
    "2. Find and lookup faces from a picture and \n",
    "3. Take a picture and look it up from existing faces\n",
    "4. Real time face recognition from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from os.path import isfile, join, splitext, split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known_face_enconding(known_face_path='./known_faces/'):\n",
    "    face_files = [f for f in listdir(known_face_path) if splitext(f)[1] in ('.jpeg','.jpg')]\n",
    "    encodings = []\n",
    "    names = []\n",
    "    for i, f in enumerate(face_files):\n",
    "        face_name = splitext(split(f)[1])[0]\n",
    "        face_image = face_recognition.load_image_file(join(known_face_path, f))\n",
    "        encodings.append(face_recognition.face_encodings(face_image)[0])\n",
    "        names.append(face_name) \n",
    "    return names, encodings\n",
    "known_names, known_encodings = known_face_enconding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize faces from a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recognize_faces_from_image(input_image, known_names, known_faces, cutoff=0.55, show_features=False):\n",
    "    names_recognized = []\n",
    "\n",
    "    # Load the jpg file into a numpy array\n",
    "    image = face_recognition.load_image_file(input_image)\n",
    "\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    # Find all facial features in all the faces in the image\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "    print(\"I found {} face(s) in this photograph.\".format(len(face_landmarks_list)))\n",
    "\n",
    "    # Let's trace out each facial feature in the image with a line!\n",
    "    pil_image = Image.fromarray(image)\n",
    "    d = ImageDraw.Draw(pil_image)    \n",
    "\n",
    "    for (top, right, bottom, left), face_encoding, face_landmarks in zip(face_locations, face_encodings, face_landmarks_list):\n",
    "\n",
    "        # Print the location of each facial feature in this image\n",
    "        facial_features = [\n",
    "            'chin',\n",
    "            'left_eyebrow',\n",
    "            'right_eyebrow',\n",
    "            'nose_bridge',\n",
    "            'nose_tip',\n",
    "            'left_eye',\n",
    "            'right_eye',\n",
    "            'top_lip',\n",
    "            'bottom_lip'\n",
    "        ]\n",
    "\n",
    "        distances = face_recognition.face_distance(known_encodings,face_encoding)\n",
    "        min_distance = np.min(distances)\n",
    "        if min_distance < cutoff:\n",
    "            face_name = known_names[np.argmin(distances)]\n",
    "            names_recognized.append(face_name)\n",
    "        else:\n",
    "            face_name = 'unknown'\n",
    "        d.text((left,top ), text=face_name)\n",
    "        d.rectangle(xy=(left,top, right, bottom))\n",
    "        if show_features:\n",
    "            for facial_feature in facial_features:\n",
    "                d.line(face_landmarks[facial_feature], width=1)\n",
    "    pil_image.show()\n",
    "    print (\"Faces recognized:\", names_recognized)    \n",
    "    return names_recognized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names, known_encodings = known_face_enconding()\n",
    "names = recognize_faces_from_image(\"./unknown_faces/unknown.jpeg\", known_names, known_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize faces from real-time video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a super simple (but slow) example of running face recognition on live video from your webcam.\n",
    "# There's a second example that's a little more complicated but runs faster.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "def recognize_faces_from_stream(known_names, known_faces, cutoff=0.55):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    try:\n",
    "        while True:\n",
    "            # Grab a single frame of video\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            # Find all the faces and face enqcodings in the frame of video\n",
    "            face_locations = face_recognition.face_locations(frame)\n",
    "            face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "            # Loop through each face in this frame of video\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                # See if the face is a match for the known face(s)\n",
    "                distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "\n",
    "                min_distance = np.min(distances)\n",
    "                if min_distance < 0.6:\n",
    "                    face_name = known_names[np.argmin(distances)]\n",
    "                else:\n",
    "                    face_name = 'unknown'   \n",
    "\n",
    "\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, face_name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            # Display the resulting image\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "            # Hit 'q' on the keyboard to quit!\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release handle to the webcam\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except:\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "686px",
    "left": "1045px",
    "right": "20px",
    "top": "115px",
    "width": "327px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
